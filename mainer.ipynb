{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Predicting Drought Using Meteorological and Soil data </h1>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Software engineering seminar - 10400</h2>\n",
    "<h2>Last edit - May 10th, 2021</h2>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Background</h3>\n",
    "Lots of text in here.."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Hypothesis</h3>\n",
    "Lots of text here as well..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "import pandas as pandas\n",
    "import seaborn as seaborn\n",
    "import matplotlib.pylab as plot_library\n",
    "from sklearn import metrics, neighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Dataset Description</h3>\n",
    "Dataset taken from Kaggle. <br>\n",
    "Derived from.. etc.."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Import meteorological data.\n",
    "train_frame = pandas.read_csv('resources/train_timeseries.csv')\n",
    "validation_frame = pandas.read_csv('resources/validation_timeseries.csv')\n",
    "test_frame = pandas.read_csv('resources/test_timeseries.csv')\n",
    "#Import soil data.\n",
    "soil_frame = pandas.read_csv('resources/soil_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Print shapes of data.\n",
    "print('The shapes of our dataframes are')\n",
    "print('train_frame', train_frame.shape)\n",
    "print('validation_frame', validation_frame.shape)\n",
    "print('test_frame', test_frame.shape)\n",
    "print('soil_frame', soil_frame.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Data Manipulating</h3>\n",
    "<h4> Empty values </h4>\n",
    "Check every imported frame for empty values. Because the target value is something measured and there <br>\n",
    "is plenty of data, empty fields will be removed rather than filled."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#train_frame manipulations.\n",
    "print(\"train_frame\\n\")\n",
    "print(\"count - \\n\", train_frame.count())\n",
    "print(\"max - \\n\", train_frame.max())\n",
    "print(\"min - \\n\", train_frame.min())\n",
    "print(\"empty amount - \\n\", train_frame.isna().any())\n",
    "print(\"empty total - \\n\", train_frame.isna().sum())\n",
    "print(\"empty precent - \\n\", train_frame.isna().sum() / len(train_frame.index) * 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#train_frame remove empty values.\n",
    "train_frame = train_frame.dropna(subset=[\"score\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#validation_frame manipulations.\n",
    "print(\"validation_frame\\n\")\n",
    "print(\"count - \\n\", validation_frame.count())\n",
    "print(\"max - \\n\", validation_frame.max())\n",
    "print(\"min - \\n\", validation_frame.min())\n",
    "print(\"empty amount - \\n\", validation_frame.isna().any())\n",
    "print(\"empty total - \\n\", validation_frame.isna().sum())\n",
    "print(\"empty precent - \\n\", validation_frame.isna().sum() / len(validation_frame.index) * 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#validation_frame remove empty values.\n",
    "validation_frame = validation_frame.dropna(subset=[\"score\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#test_frame manipulations.\n",
    "print(\"test_frame\\n\")\n",
    "print(\"count - \\n\", test_frame.count())\n",
    "print(\"max - \\n\", test_frame.max())\n",
    "print(\"min - \\n\", test_frame.min())\n",
    "print(\"empty amount - \\n\", test_frame.isna().any())\n",
    "print(\"empty total - \\n\", test_frame.isna().sum())\n",
    "print(\"empty precent - \\n\", test_frame.isna().sum() / len(test_frame.index) * 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#test_frame remove empty values.\n",
    "test_frame = test_frame.dropna(subset=[\"score\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#soil_frame manipulations.\n",
    "print(\"soil_frame\\n\")\n",
    "print(\"count - \\n\", soil_frame.count())\n",
    "print(\"max - \\n\", soil_frame.max())\n",
    "print(\"min - \\n\", soil_frame.min())\n",
    "print(\"empty amount - \\n\", soil_frame.isna().any())\n",
    "print(\"empty total - \\n\", soil_frame.isna().sum())\n",
    "print(\"empty precent - \\n\", soil_frame.isna().sum() / len(soil_frame.index) * 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#soil_frame doesn't have empty cells.\n",
    "#Print update shapes of data.\n",
    "print('The updated shapes of our dataframes are')\n",
    "print('train_frame', train_frame.shape)\n",
    "print('validation_frame', validation_frame.shape)\n",
    "print('test_frame', test_frame.shape)\n",
    "print('soil_frame', soil_frame.shape)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4> Merging Data </h4>\n",
    "Merging the meteorological data with the soil data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Merge train_frame and soil_frame.\n",
    "train_soil_frame = pandas.merge(train_frame, soil_frame, how='inner', on='fips')\n",
    "train_soil_frame.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Merge validation_frame and soil_frame.\n",
    "validation_soil_frame = pandas.merge(validation_frame, soil_frame, how='inner', on='fips')\n",
    "validation_soil_frame.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Merge test_frame and soil_frame.\n",
    "test_soil_frame = pandas.merge(test_frame, soil_frame, how='inner', on='fips')\n",
    "test_soil_frame.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Merge all frames together.\n",
    "total_frame = pandas.concat([train_soil_frame, validation_soil_frame, test_soil_frame])\n",
    "total_frame.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove 'fips' and 'date' columns as we do not need their influence in the calculations. <br>\n",
    "We want to find the correlation between meteorological and soil data to the drought 'score' column."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Remove fips column\n",
    "del total_frame[\"fips\"]\n",
    "\n",
    "#Remove date column\n",
    "del total_frame[\"date\"]\n",
    "\n",
    "#Remove latitude column\n",
    "del total_frame[\"lat\"]\n",
    "\n",
    "#Remove longitude column\n",
    "del total_frame[\"lon\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Finished</h4>\n",
    "Now we have the finished data frame to work on."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total_frame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Correlation Testing</h4>\n",
    "Test whether there are any columns which poorly affect the score target value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Pearson test for total correlation checking\n",
    "fig, ax = plot_library.subplots(figsize=(75, 50))\n",
    "seaborn.heatmap(total_frame.corr(method='pearson'), annot=True, ax=ax, cmap=plot_library.cm.Blues)\n",
    "plot_library.savefig('total_frame_corr.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Splitting the columns to find the biggest correlation with score."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Meteorological and drought\n",
    "fig, ax = plot_library.subplots(figsize=(20, 15))\n",
    "seaborn.heatmap(total_frame[['PRECTOT', 'PS',\n",
    "                                        'QV2M', 'T2M',\n",
    "                                        'T2MDEW', 'T2MWET',\n",
    "                                        'T2M_MAX', 'T2M_MIN',\n",
    "                                        'T2M_RANGE', 'TS',\n",
    "                                        'WS10M', 'WS10M_MAX',\n",
    "                                        'WS10M_MIN', 'WS10M_RANGE',\n",
    "                                        'WS50M', 'WS50M_MAX',\n",
    "                                        'WS50M_MIN', 'WS50M_RANGE',\n",
    "                                        'score']].corr(method='pearson'),\n",
    "                           annot=True, ax=ax, cmap=plot_library.cm.Blues)\n",
    "plot_library.savefig('meteorolgical_corr.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Soil and drought\n",
    "fig, ax = plot_library.subplots(figsize=(25, 20))\n",
    "seaborn.heatmap(total_frame[['elevation', 'slope1',\n",
    "                                        'slope2', 'slope3',\n",
    "                                        'slope4', 'slope5',\n",
    "                                        'slope6', 'slope7',\n",
    "                                        'slope8', 'aspectN',\n",
    "                                        'aspectW', 'aspectE',\n",
    "                                        'aspectS', 'aspectUnknown',\n",
    "                                        'WAT_LAND', 'NVG_LAND',\n",
    "                                        'URB_LAND', 'GRS_LAND',\n",
    "                                        'FOR_LAND', 'CULTRF_LAND',\n",
    "                                        'CULTIR_LAND', 'CULT_LAND',\n",
    "                                        'SQ1', 'SQ2',\n",
    "                                        'SQ3', 'SQ4',\n",
    "                                        'SQ5', 'SQ6',\n",
    "                                        'SQ7', 'score']].corr(method='pearson'),\n",
    "                           annot=True, ax=ax, cmap=plot_library.cm.Blues)\n",
    "plot_library.savefig('soil_corr.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Higher correlation numbers closeup.\n",
    "fig, ax = plot_library.subplots(figsize=(6, 5))\n",
    "seaborn.heatmap(total_frame[['T2M_RANGE', 'T2M_MAX','elevation', 'NVG_LAND',\n",
    "                                        'GRS_LAND', 'CULTRF_LAND', 'score']].corr(method='pearson'),\n",
    "                           annot=True, ax=ax, cmap=plot_library.cm.Blues)\n",
    "plot_library.savefig('closeup_corr.png')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4> Imbalanced Dataset <h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score_balance = []\n",
    "\n",
    "for i in range(0,6):\n",
    "    tempRows = total_frame[(total_frame['score'] >= i) & (total_frame['score'] < (i + 1))]\n",
    "    score_balance.append(len(tempRows))\n",
    "\n",
    "print(\"Distribution of score classes. From 0 to 5.\")\n",
    "for j in score_balance:\n",
    "    print()\n",
    "    print(f\"Amount is {j}. Which are {j / sum(score_balance) * 100:.3}%.\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Separation of target and features<h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Classification preparation\n",
    "# Extract the training and test data\n",
    "data = total_frame\n",
    "X = data[['PRECTOT', 'PS', 'QV2M', 'T2M', 'T2MDEW', 'T2MWET',\n",
    "          'T2M_MAX', 'T2M_MIN', 'T2M_RANGE', 'TS', 'WS10M', 'WS10M_MAX',\n",
    "          'WS10M_MIN', 'WS10M_RANGE', 'WS50M', 'WS50M_MAX', 'WS50M_MIN',\n",
    "          'WS50M_RANGE', 'elevation', 'slope1', 'slope2', 'slope3', 'slope4',\n",
    "          'slope5', 'slope6', 'slope7', 'slope8', 'aspectN', 'aspectW',\n",
    "          'aspectE', 'aspectS', 'aspectUnknown', 'WAT_LAND', 'NVG_LAND',\n",
    "          'URB_LAND', 'GRS_LAND', 'FOR_LAND', 'CULTRF_LAND', 'CULTIR_LAND',\n",
    "          'CULT_LAND', 'SQ1', 'SQ2', 'SQ3', 'SQ4', 'SQ5', 'SQ6', 'SQ7']]\n",
    "y = data['score'].apply(numpy.floor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Separation into training and test sets<h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Split into training and test. 30/70.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Algorithms</h3>\n",
    "Both regression and classifier algorithms will be utilized."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Random Forest</h4>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Regression preparation\n",
    "#Extract the training and test data\n",
    "data_reg = total_frame.values\n",
    "X_reg = data_reg[:, 1:]  # all rows, no label\n",
    "y_reg = data_reg[:, 18]  # all rows, label only"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Split into training and test. 30/70.\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Establish model with different amounts of estimators.\n",
    "RFRmodel = RandomForestRegressor(n_jobs=-1)\n",
    "#5 estimators\n",
    "RFRmodel.set_params(n_estimators=5)\n",
    "RFRmodel.fit(X_reg_train, y_reg_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Score value for determining accuracy.\n",
    "RFR_score = RFRmodel.score(X_reg_test, y_reg_test)\n",
    "print(f'Score value for 5 estimators is {RFR_score}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Root median square as a measure of accuracy.\n",
    "RFR_y_pred = RFRmodel.predict(X_reg_test)\n",
    "print(\"RMS: %r \" % numpy.sqrt(numpy.mean((y_train - y_test) ** 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Establish classification model.\n",
    "RFC_model = RandomForestClassifier(n_jobs=-1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RFC_model.set_params()\n",
    "RFC_model.fit(X_train, y_train)\n",
    "RFC_y_pred = RFC_model.predict(X_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Training accuracy\", RFC_model.score(X_train, y_train))\n",
    "print(\"Testing accuracy\", RFC_model.score(X_test, y_test))\n",
    "RFC_score = metrics.accuracy_score(y_test, RFC_y_pred)\n",
    "print(\"Accuracy:\", RFC_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(y_test, RFC_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, RFC_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display = plot_confusion_matrix(RFC_model, X_test, y_test,\n",
    "                                cmap=plot_library.cm.Blues ,\n",
    "                                normalize=None)\n",
    "\n",
    "plot_library.savefig('confusionRFC.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Multinomial Naive Bayes <h3>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Scale the data between 0 and 1.\n",
    "scaler = MinMaxScaler(feature_range=[0,1])\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CNB_model = ComplementNB()\n",
    "CNB_model.fit(X_train, y_train)\n",
    "CNB_y_pred = CNB_model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Training accuracy\", CNB_model.score(X_train, y_train))\n",
    "print(\"Testing accuracy\", CNB_model.score(X_test, y_test))\n",
    "CNB_score = metrics.accuracy_score(y_test, CNB_y_pred)\n",
    "print(\"Accuracy:\", CNB_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(y_test, CNB_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, CNB_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display = plot_confusion_matrix(CNB_model, X_test, y_test,\n",
    "                                cmap=plot_library.cm.Blues ,\n",
    "                                normalize=None)\n",
    "\n",
    "plot_library.savefig('confusionNB.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Logistic Regression<h3>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LR_model = LogisticRegression(solver='sag', multi_class='multinomial')\n",
    "LR_model.fit(X_train, y_train)\n",
    "LR_y_pred = LR_model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Training accuracy\", LR_model.score(X_train, y_train))\n",
    "print(\"Testing accuracy\", LR_model.score(X_test, y_test))\n",
    "LR_score = metrics.accuracy_score(y_test, LR_y_pred)\n",
    "print(\"Accuracy:\", LR_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(y_test, LR_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, LR_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display = plot_confusion_matrix(LR_model, X_test, y_test,\n",
    "                                cmap=plot_library.cm.Blues ,\n",
    "                                normalize=None)\n",
    "\n",
    "plot_library.savefig('confusionLR.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# K nearest neighbors redacted for taking way too long to predict values."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#scaling to decrease running time.\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train_tran = scaler.transform(X_train)\n",
    "# X_test_tran = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# KNN_model = neighbors.KNeighborsClassifier(n_jobs=-1, n_neighbors=1)\n",
    "# KNN_model.fit(X_train_tran, y_train)\n",
    "# KNN_y_pred = KNN_model.predict(X_test_tran)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(\"Training accuracy\", KNN_model.score(X_train_tran, y_train))\n",
    "# print(\"Testing accuracy\", KNN_model.score(X_test_tran, y_test))\n",
    "# print(\"Accuracy:\", metrics.accuracy_score(y_test, KNN_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, KNN_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(confusion_matrix(y_test, KNN_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# display = plot_confusion_matrix(KNN_model, X_test_tran, y_test,\n",
    "#                                 cmap=plot_library.cm.Blues ,\n",
    "#                                 normalize=None)\n",
    "#\n",
    "# plot_library.savefig('confusionKNN.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Retry with different params<h3>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "#Classification preparation\n",
    "# Extract the training and test data\n",
    "data = total_frame\n",
    "X = data[['T2M_RANGE', 'T2M_MAX','elevation',\n",
    "          'NVG_LAND', 'GRS_LAND', 'CULTRF_LAND']]\n",
    "y = data['score'].apply(numpy.floor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Separation into training and test sets<h4>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "#Split into training and test. 30/70.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Algorithms</h3>\n",
    "Both regression and classifier algorithms will be utilized."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h4>Random Forest</h4>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "#Regression preparation\n",
    "#Extract the training and test data\n",
    "data_reg = total_frame.values\n",
    "X_reg = data_reg[:, 1:]  # all rows, no label\n",
    "y_reg = data_reg[:, 7]  # all rows, label only"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "#Split into training and test. 30/70.\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-84-5eb7b8d2c0a3>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m#5 estimators\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mRFRmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_estimators\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mRFRmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_reg_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_reg_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nahum\\documents\\projects\\python\\seminar\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    385\u001B[0m             \u001B[1;31m# parallel_backend contexts set at a higher level,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    386\u001B[0m             \u001B[1;31m# since correctness does not rely on using threads.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 387\u001B[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001B[0m\u001B[0;32m    388\u001B[0m                              \u001B[1;33m**\u001B[0m\u001B[0m_joblib_parallel_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprefer\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'threads'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    389\u001B[0m                 delayed(_parallel_build_trees)(\n",
      "\u001B[1;32mc:\\users\\nahum\\documents\\projects\\python\\seminar\\venv\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1052\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mretrieval_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1054\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mretrieve\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1055\u001B[0m             \u001B[1;31m# Make sure that we get a last message telling us we are done\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1056\u001B[0m             \u001B[0melapsed_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_start_time\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nahum\\documents\\projects\\python\\seminar\\venv\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mretrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    931\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    932\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'supports_timeout'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 933\u001B[1;33m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    934\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    935\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\pool.py\u001B[0m in \u001B[0;36mget\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    763\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    764\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 765\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    766\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mready\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    767\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\pool.py\u001B[0m in \u001B[0;36mwait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    760\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    761\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mwait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 762\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_event\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    763\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    764\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py\u001B[0m in \u001B[0;36mwait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    572\u001B[0m             \u001B[0msignaled\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_flag\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    573\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0msignaled\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 574\u001B[1;33m                 \u001B[0msignaled\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_cond\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    575\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0msignaled\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    576\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py\u001B[0m in \u001B[0;36mwait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    310\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m    \u001B[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    311\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 312\u001B[1;33m                 \u001B[0mwaiter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    313\u001B[0m                 \u001B[0mgotit\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    314\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Establish model with different amounts of estimators.\n",
    "RFRmodel = RandomForestRegressor(n_jobs=-1)\n",
    "#5 estimators\n",
    "RFRmodel.set_params(n_estimators=5)\n",
    "RFRmodel.fit(X_reg_train, y_reg_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Score value for determining accuracy.\n",
    "RFR_score = RFRmodel.score(X_reg_test, y_reg_test)\n",
    "print(f'Score value for 5 estimators is {RFR_score}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Root median square as a measure of accuracy.\n",
    "RFR_y_pred = RFRmodel.predict(X_reg_test)\n",
    "print(\"RMS: %r \" % numpy.sqrt(numpy.mean((y_train - y_test) ** 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "#Establish classification model.\n",
    "RFC_model = RandomForestClassifier(n_jobs=-1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "RFC_model.set_params()\n",
    "RFC_model.fit(X_train, y_train)\n",
    "RFC_y_pred = RFC_model.predict(X_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy 0.9998041482819778\n",
      "Testing accuracy 0.6439699739018369\n",
      "Accuracy: 0.6439699739018369\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy\", RFC_model.score(X_train, y_train))\n",
    "print(\"Testing accuracy\", RFC_model.score(X_test, y_test))\n",
    "RFC_score = metrics.accuracy_score(y_test, RFC_y_pred)\n",
    "print(\"Accuracy:\", RFC_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.91      0.80    691175\n",
      "         1.0       0.23      0.10      0.14    152193\n",
      "         2.0       0.19      0.08      0.11     90883\n",
      "         3.0       0.17      0.07      0.09     55138\n",
      "         4.0       0.13      0.04      0.07     25794\n",
      "         5.0       0.15      0.05      0.07      6728\n",
      "\n",
      "    accuracy                           0.64   1021911\n",
      "   macro avg       0.26      0.21      0.21   1021911\n",
      "weighted avg       0.54      0.64      0.58   1021911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, RFC_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[631480  30852  15753   8870   3491    729]\n",
      " [125068  14737   6831   3722   1464    371]\n",
      " [ 70964   8379   6837   3135   1280    288]\n",
      " [ 40786   5568   3832   3595   1113    244]\n",
      " [ 18350   2816   1888   1447   1122    171]\n",
      " [  4584    763    525    336    211    309]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, RFC_y_pred))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Multinomial Naive Bayes <h3>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "# Scale the data between 0 and 1.\n",
    "scaler = MinMaxScaler(feature_range=[0,1])\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "CNB_model = ComplementNB()\n",
    "CNB_model.fit(X_train, y_train)\n",
    "CNB_y_pred = CNB_model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy 0.45419858693195136\n",
      "Testing accuracy 0.4541373955266163\n",
      "Accuracy: 0.4541373955266163\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy\", CNB_model.score(X_train, y_train))\n",
    "print(\"Testing accuracy\", CNB_model.score(X_test, y_test))\n",
    "CNB_score = metrics.accuracy_score(y_test, CNB_y_pred)\n",
    "print(\"Accuracy:\", CNB_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.62      0.67    691175\n",
      "         1.0       0.13      0.00      0.00    152193\n",
      "         2.0       0.15      0.13      0.14     90883\n",
      "         3.0       0.07      0.41      0.12     55138\n",
      "         4.0       0.03      0.02      0.03     25794\n",
      "         5.0       0.01      0.00      0.00      6728\n",
      "\n",
      "    accuracy                           0.45   1021911\n",
      "   macro avg       0.19      0.20      0.16   1021911\n",
      "weighted avg       0.53      0.45      0.47   1021911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, CNB_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[429072    282  37001 208992  15620    208]\n",
      " [ 83696     50  14135  50979   3248     85]\n",
      " [ 44407     18  11506  33073   1812     67]\n",
      " [ 23016     19   8023  22821   1213     46]\n",
      " [ 10114      6   3769  11249    633     23]\n",
      " [  2676      0    642   3241    163      6]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, CNB_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Logistic Regression<h3>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "LR_model = LogisticRegression(solver='sag', multi_class='multinomial')\n",
    "LR_model.fit(X_train, y_train)\n",
    "LR_y_pred = LR_model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy 0.6759278946946831\n",
      "Testing accuracy 0.6763084065050675\n",
      "Accuracy: 0.6763084065050675\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy\", LR_model.score(X_train, y_train))\n",
    "print(\"Testing accuracy\", LR_model.score(X_test, y_test))\n",
    "LR_score = metrics.accuracy_score(y_test, LR_y_pred)\n",
    "print(\"Accuracy:\", LR_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nahum\\documents\\projects\\python\\seminar\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\nahum\\documents\\projects\\python\\seminar\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      1.00      0.81    691175\n",
      "         1.0       0.00      0.00      0.00    152193\n",
      "         2.0       0.22      0.00      0.00     90883\n",
      "         3.0       0.17      0.00      0.00     55138\n",
      "         4.0       0.00      0.00      0.00     25794\n",
      "         5.0       0.00      0.00      0.00      6728\n",
      "\n",
      "    accuracy                           0.68   1021911\n",
      "   macro avg       0.18      0.17      0.13   1021911\n",
      "weighted avg       0.49      0.68      0.55   1021911\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nahum\\documents\\projects\\python\\seminar\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, LR_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[691078      0     44     53      0      0]\n",
      " [152147      0     19     27      0      0]\n",
      " [ 90831      0     24     28      0      0]\n",
      " [ 55098      0     15     25      0      0]\n",
      " [ 25775      0      7     12      0      0]\n",
      " [  6727      0      0      1      0      0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, LR_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}